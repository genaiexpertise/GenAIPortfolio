{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c06332-f2fb-4cba-bfdb-b7610f91e73e",
   "metadata": {},
   "source": [
    "# How to build a simple LLM App with LangChain and deploy it with LangServe\n",
    "* Very simple LLM App.\n",
    "* Goal of the App: translate text from English into another language.\n",
    "* Second version: how to build this app using a language other than English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ee60d5-1896-4c6a-aa4e-65da81b82830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e38fae-79ce-4db1-9c73-07d38aaa3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cefb53-e159-4f08-938d-448a0160d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messagesToTheLLM = [\n",
    "    SystemMessage(content=\"Translate the following from English into Yoruba\"),\n",
    "    HumanMessage(content=\"Generative AI is the greatest value-creation opportunity in Human History.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3fecee-ef48-4c90-a690-68803e5a3aa1",
   "metadata": {},
   "source": [
    "### Step 1: call the LLM¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d2344d-21e3-44f5-b725-aa5ceda9565a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI ti o dara julọ ni ṣiṣẹ ayẹ lọdọ ilẹ-ẹkọ enia.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 34, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f0ca5e98-3bc0-4fb7-aac8-6d8af4d62bb0-0', usage_metadata={'input_tokens': 34, 'output_tokens': 34, 'total_tokens': 68})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messagesToTheLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49e547-256b-4127-aff3-218fa3b6e2cd",
   "metadata": {},
   "source": [
    "### Use an Output Parser to format the response of the LLM as a string of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9911e42-17d2-4eb4-a342-2e7a36cb519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c0506-f5e3-48cb-89ca-a6fa6fec4b32",
   "metadata": {},
   "source": [
    "#### Step 1: call the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b95088a-fc65-430d-a84b-7008f028a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialResponse = llm.invoke(messagesToTheLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d438030-2b0b-416b-8272-7e07eecd4950",
   "metadata": {},
   "source": [
    "#### Step 2: apply the parser to format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2b2ef1-24a9-4d92-be85-1c411588db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedResponse = parser.invoke(initialResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88704636-ad0f-4a2b-880e-3faff2f320cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI ti o tobi ni akoko ti o dara lati se ibeere lati se alaye ni orilẹ-ede ènìyàn.\n"
     ]
    }
   ],
   "source": [
    "print(formattedResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009c97b-9098-4414-93d7-571df3b2665e",
   "metadata": {},
   "source": [
    "### Chain the LLM Call and the Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c615f9-14a8-43dd-afb9-01ddc7ac7c9d",
   "metadata": {},
   "source": [
    "#### Steps 1 and 2: call the LLM and apply the parser to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f131817e-2e59-4514-8788-c48ba9ab15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmAndParserChained = llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf581401-ddd8-49d7-9956-11e4e59aa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responseFromChain=llmAndParserChained.invoke(messagesToTheLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239f4725-bfd2-47da-8841-f9f685534519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI ti a gbajumo ti o dara lati se alaye ti o dun lati odo alaye aiye.\n"
     ]
    }
   ],
   "source": [
    "print(responseFromChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08023401-d56e-4758-92b5-e86ed4be1397",
   "metadata": {},
   "source": [
    "### Use a Prompt Template with a System Message and Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c4a3db-6619-4ee0-a37a-fbf7cfe0f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d69d93a-4235-42ed-9a2a-c9f2ac486f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following text input into {language}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307080af-625e-4bdd-a54d-9b56a1495806",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template), \n",
    "        (\"user\", \"{text_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb02f8e5-cc63-4729-83e6-8aac16c4dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SecondChain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe4f1a5-82b0-4cb1-864d-c3eca66f0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResponseFromTheLLM = SecondChain.invoke(\n",
    "    {\n",
    "    \"language\": \"Spanish\",\n",
    "    \"text_input\": \"Now is the moment to learn Generative AI!\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a520a01-797f-4750-9dd0-80b0ca928c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Ahora es el momento de aprender Inteligencia Artificial Generativa!\n"
     ]
    }
   ],
   "source": [
    "print(ResponseFromTheLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804656c-c6a0-4bf4-b526-b908e03a6f9e",
   "metadata": {},
   "source": [
    "### Deploy the App using LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b7f88e-fd1f-435a-9aaf-ac3b800c09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langserve[all]\n",
      "  Downloading langserve-0.2.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langserve[all]) (0.27.2)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langserve[all]) (0.2.38)\n",
      "Requirement already satisfied: orjson>=2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langserve[all]) (3.10.7)\n",
      "Requirement already satisfied: pydantic>=1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langserve[all]) (2.8.2)\n",
      "Collecting pyproject-toml<0.0.11,>=0.0.10 (from langserve[all])\n",
      "  Downloading pyproject_toml-0.0.10-py3-none-any.whl.metadata (642 bytes)\n",
      "Requirement already satisfied: fastapi<1,>=0.90.1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langserve[all]) (0.113.0)\n",
      "Collecting sse-starlette<2.0.0,>=1.3.0 (from langserve[all])\n",
      "  Downloading sse_starlette-1.8.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from fastapi<1,>=0.90.1->langserve[all]) (0.38.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from fastapi<1,>=0.90.1->langserve[all]) (4.12.2)\n",
      "Requirement already satisfied: anyio in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpx>=0.23.0->langserve[all]) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpx>=0.23.0->langserve[all]) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpx>=0.23.0->langserve[all]) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpx>=0.23.0->langserve[all]) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpx>=0.23.0->langserve[all]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.23.0->langserve[all]) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1->langserve[all]) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1->langserve[all]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1->langserve[all]) (0.1.114)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1->langserve[all]) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1->langserve[all]) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pydantic>=1->langserve[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pydantic>=1->langserve[all]) (2.20.1)\n",
      "Requirement already satisfied: setuptools>=42 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (68.1.2)\n",
      "Requirement already satisfied: wheel in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (0.41.2)\n",
      "Requirement already satisfied: toml in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (0.10.2)\n",
      "Requirement already satisfied: jsonschema in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (4.23.0)\n",
      "Requirement already satisfied: uvicorn in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from sse-starlette<2.0.0,>=1.3.0->langserve[all]) (0.30.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1->langserve[all]) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1->langserve[all]) (2.31.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from anyio->httpx>=0.23.0->langserve[all]) (1.2.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve[all]) (0.20.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from uvicorn->sse-starlette<2.0.0,>=1.3.0->langserve[all]) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1->langserve[all]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teejay/dev/toraagloballab/venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1->langserve[all]) (2.1.0)\n",
      "Downloading pyproject_toml-0.0.10-py3-none-any.whl (6.9 kB)\n",
      "Downloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
      "Downloading langserve-0.2.3-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sse-starlette, pyproject-toml, langserve\n",
      "Successfully installed langserve-0.2.3 pyproject-toml-0.0.10 sse-starlette-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install \"langserve[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d9f1f-53b8-4fa3-8bc8-f5a682ca6958",
   "metadata": {},
   "source": [
    "## What if we wanted to build this application in a foreign language, meaning we communicate with the LLM model in a foreign language instead of in English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2ddc8-850d-4cad-87a9-216c714f7862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
